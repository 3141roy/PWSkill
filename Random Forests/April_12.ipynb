{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b4eed8-ce2f-4941-993d-fa5e5d66b013",
   "metadata": {},
   "source": [
    "### Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113764d-c7ae-4d8a-a6a2-623aaa3daffc",
   "metadata": {},
   "source": [
    "A descision tree trained on the entire data has low bias because it is very accurate but generally has higher variance as the DT tends to overfit/ memorize the training data if we dont control its depth.\n",
    "\n",
    "By using Bootstrap aggregation, we can have multiple Descision Trees. In doing so we keep our bias low as it is still trained on the same random sampling of our data and at the same time habving multiple trees eventually gives us a more accurate aggreagate value. \n",
    "\n",
    "By combining the predictions of the different trees, the overall prediction error can be reduced, especially when the individual trees are highly correlated and prone to overfitting. This is because bagging can reduce the effect of individual noisy or biased trees and promote the generalization of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a313f-0a10-4683-b102-d8be1b9468c0",
   "metadata": {},
   "source": [
    "### Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceecfb6d-bce7-4619-8b67-06627c31e6c9",
   "metadata": {},
   "source": [
    "Bagging offers the advantage of allowing many weak learners to combine efforts to outdo a single strong learner helping in the reduction of variance.\n",
    "\n",
    "One disadvantage of bagging is that it introduces a loss of interpretability of a model. The resultant model can experience lots of bias when the proper procedure is ignored. Despite bagging being highly accurate, it can be computationally expensive, which may discourage its use in certain instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8edc-7b08-4623-8ad9-60d9b7315658",
   "metadata": {},
   "source": [
    "### Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0588f26-7db0-4eec-a63c-8f5c69544996",
   "metadata": {},
   "source": [
    "When using bagging, the base learners are trained on different samples of the data, and their predictions are combined to form the final prediction. This can help to reduce the variance of the model, as the errors of the individual base learners tend to cancel out. However, the bias of the model can increase if the base learners are too simple or limited in their capacity to capture the underlying patterns in the data.\n",
    "\n",
    "The choice of base learner can influence the balance between bias and variance in the bagged model. For example, if the base learner is a decision tree, which tends to have high variance and low bias, the bagged model can reduce the variance and improve the generalization performance. On the other hand, if the base learner is a linear regression, which tends to have low variance and high bias, the bagged model may not be able to reduce the bias and may not improve the performance significantly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07edc3fc-a2b2-4380-b625-d6025bfb4603",
   "metadata": {},
   "source": [
    "### Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61832b64-d0cf-4bba-9bd5-e7d02d798d87",
   "metadata": {},
   "source": [
    "Yes, we can use Bagging for both classification and regression, the only difference being the way in which we evaluate the final descision\n",
    "\n",
    "In case of Classification, we take the most common outcome out of all the results from our base learners.\n",
    "\n",
    "In case of Regression, we simply calculate the avareage of all the given values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712daa2-76a4-4aad-8548-d1ae5581294b",
   "metadata": {},
   "source": [
    "### Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0259b-7509-4a9e-8931-304d78ffe24d",
   "metadata": {},
   "source": [
    "The ensemble size in bagging refers to the number of base learners that are used to generate the final prediction. The choice of ensemble size can have an impact on the performance of the bagging model.\n",
    "\n",
    "Increasing the ensemble size can improve the performance of the bagging model up to a certain point. With more base learners, the variance of the model is reduced, and the prediction becomes more stable and accurate. However, after a certain point, the performance improvement may plateau, or even start to decrease, due to overfitting or increased computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46780284-59bd-4dc0-acb9-e5c22130abd9",
   "metadata": {},
   "source": [
    "### Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143af11b-747d-49bd-9645-aa5673b287ef",
   "metadata": {},
   "source": [
    "Medical diagnosis: Bagging can be used to improve the accuracy of medical diagnosis by combining the predictions of multiple classifiers. For example, a bagged ensemble of decision trees can be used to predict the likelihood of a patient having a certain disease based on their symptoms and medical history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792b1c0-5541-4cd0-85ba-c9e09d21f3e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
